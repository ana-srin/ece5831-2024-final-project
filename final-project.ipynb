{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Convolutional Neural Networks Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1]. Nithin Sai Adupa, [2]. Saadhana Srinath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = tf.keras.Input(shape=(28, 28, 1))\n",
    "    \n",
    "    # Convolution layer 1 with 16 filters\n",
    "    x = layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='Conv2D_1')(input_layer)\n",
    "    \n",
    "    # Downsampling layer 1 (Max Pooling)\n",
    "    x = layers.MaxPooling2D((2, 2), name='MaxPooling2D_1')(x)\n",
    "    \n",
    "    # Convolution layer 2 with 32 filters\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='Conv2D_2')(x)\n",
    "    \n",
    "    # Downsampling layer 2 (Max Pooling)\n",
    "    x = layers.MaxPooling2D((2, 2), name='MaxPooling2D_2')(x)\n",
    "    \n",
    "    # Flatten and Fully-connected (Dense) layers\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Fully-connected layer 1 with 64 nodes\n",
    "    x = layers.Dense(64, activation='relu', name='Dense_1')(x)\n",
    "    \n",
    "    # Fully-connected layer 2 with 32 nodes\n",
    "    x = layers.Dense(32, activation='relu', name='Dense_2')(x)\n",
    "    \n",
    "    # Output layer with 10 nodes (for 10 classes)\n",
    "    output_layer = layers.Dense(10, activation='softmax', name='Output')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " Conv2D_1 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " MaxPooling2D_1 (MaxPooling  (None, 14, 14, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Conv2D_2 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " MaxPooling2D_2 (MaxPooling  (None, 7, 7, 32)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 64)                100416    \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107626 (420.41 KB)\n",
      "Trainable params: 107626 (420.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model that will return the intermediate layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "intermediate_model = models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to preprocess the drawing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=(0, -1)) \n",
    "    img_array = img_array / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to add color to the feature maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_color_to_feature_map(feature_map):\n",
    "    colored_map = cv2.applyColorMap(feature_map, cv2.COLORMAP_JET)\n",
    "    return colored_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to plot the processed nodes in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_maps(layer_indices, feature_maps):\n",
    "    max_display_size = 150\n",
    "    margin = 10\n",
    "    node_margin = 2 \n",
    "    width_needed = (max_display_size + margin) * len(layer_indices) + margin\n",
    "    height_needed = max_display_size + 40  \n",
    "\n",
    "    output_img = np.ones((height_needed, width_needed, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    y_offset = 10\n",
    "\n",
    "    for idx, layer_index in enumerate(layer_indices):\n",
    "        features = feature_maps[layer_index]\n",
    "        layer_name = model.layers[layer_index].name\n",
    "\n",
    "        if len(features.shape) == 4: \n",
    "            num_filters = features.shape[-1]\n",
    "            size = features.shape[1]\n",
    "\n",
    "            grid_cols = int(np.ceil(np.sqrt(num_filters)))\n",
    "            grid_rows = int(np.ceil(num_filters / grid_cols))\n",
    "            canvas_size = size + node_margin\n",
    "            display_grid = np.zeros((canvas_size * grid_rows, canvas_size * grid_cols), dtype=np.uint8)\n",
    "\n",
    "            for i in range(num_filters):\n",
    "                x = features[0, :, :, i]\n",
    "                x -= x.mean()\n",
    "                x /= (x.std() + 1e-5)\n",
    "                x *= 64\n",
    "                x += 128\n",
    "                x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "                row = i // grid_cols\n",
    "                col = i % grid_cols\n",
    "                display_grid[row * canvas_size:(row * canvas_size + size), col * canvas_size:(col * canvas_size + size)] = x\n",
    "\n",
    "            display_grid = add_color_to_feature_map(display_grid)\n",
    "            display_grid = cv2.resize(display_grid, (max_display_size, max_display_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            x_offset = margin + (idx * (max_display_size + margin))\n",
    "            output_img[y_offset:y_offset + max_display_size, x_offset:x_offset + max_display_size] = display_grid\n",
    "\n",
    "            cv2.putText(output_img, layer_name, (x_offset, y_offset + max_display_size + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        elif len(features.shape) == 2:\n",
    "            fig = plt.figure(figsize=(1.5, 1.5))\n",
    "            plt.bar(range(features.shape[1]), features[0])\n",
    "            plt.ylim(0, 1)\n",
    "            plt.axis('off')\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(fig)\n",
    "            buf.seek(0)\n",
    "            bar_img = np.array(Image.open(buf))\n",
    "            bar_img = cv2.resize(bar_img, (max_display_size, max_display_size))\n",
    "\n",
    "            x_offset = margin + (idx * (max_display_size + margin))\n",
    "            bar_img = cv2.cvtColor(bar_img, cv2.COLOR_RGBA2BGR)\n",
    "            h, w = bar_img.shape[:2]\n",
    "            output_img[y_offset:y_offset + h, x_offset:x_offset + w] = bar_img\n",
    "\n",
    "            cv2.putText(output_img, layer_name, (x_offset, y_offset + h + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Output', output_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_width, canvas_height = 200, 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an OpenCV canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ones((canvas_width, canvas_height, 3), np.uint8) * 255\n",
    "\n",
    "drawing = False\n",
    "ix, iy = -1, -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mouse callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, img\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cv2.line(img, (ix, iy), (x, y), (0, 0, 0), 3)\n",
    "            ix, iy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.line(img, (ix, iy), (x, y), (0, 0, 0), 3)\n",
    "        update_feature_maps()\n",
    "\n",
    "def update_feature_maps():\n",
    "    global img\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    preprocessed_img = preprocess_image(pil_img)\n",
    "    feature_maps = intermediate_model.predict(preprocessed_img)\n",
    "    plot_feature_maps(range(len(model.layers)), feature_maps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seting up the OpenCV window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Draw')\n",
    "cv2.setMouseCallback('Draw', draw_circle)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    cv2.imshow('Draw', img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
